{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSAvjs+efSe81BgkUVqUrY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingzibu/ODE/blob/main/learn/ODE_adjoint_sensitivities_of_a_linear_systems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=dKqoXFULsbQ&list=PLISXH-iEM4Jk27AmSvISooRRKH4WtlWKP&index=3"
      ],
      "metadata": {
        "id": "ATxv4E4ReBXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear system**\n",
        "\n",
        "$Ax = b$ -> solve x -> loss function, reference solution $x_r$, loss function could be $J = \\frac{1}{2} (x - x_r)^⊤ (x-x_r)$\n",
        "\n"
      ],
      "metadata": {
        "id": "HGTjUhSQeD4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$A x = b (\\theta)$\n",
        "\n",
        "sensitivities: $\\frac{dJ}{d\\theta}$?\n",
        "\n",
        "Here:\n",
        "\n",
        "$A \\in \\mathbf{R}^{3 \\times 3}$, fixed\n",
        "\n",
        "$b$ variable, parameter dependent, $b = [\\theta_0, \\theta_1, \\theta_2]$, but we guess\n",
        "\n",
        "\n",
        "Solve \"classical\" problem\n",
        "\n",
        "1. solve $Ax = \\hat{b}$ for $x$, can be solved by python\n",
        "\n",
        "   evaluate $J = \\frac{1}{2} (x - x_r)^⊤ (x-x_r)$\n",
        "\n",
        "2. Obtain the gradients $\\frac{dJ}{d\\theta}$, the gradient is a row vector\n",
        "\n"
      ],
      "metadata": {
        "id": "EmFyzf-jek-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. finite differences\n",
        "\n",
        "   $\\frac{dJ}{d\\theta} = [\\frac{dJ}{d\\theta_0}, \\frac{dJ}{d\\theta_1},\\frac{dJ}{d\\theta_2}]$\n",
        "\n",
        "   for $\\frac{dJ}{d\\theta_0}$: $̃\\tilde{b} = \\hat{b} + ϵe_0$, solve $A\\tilde{x} = \\tilde{b}$ for $\\tilde{x}$\n",
        "\n",
        "   Evaluate $\\tilde{J} = \\frac{1}{2} (\\tilde{x} - x_r)^⊤ (\\tilde{x}-x_r)$\n",
        "\n",
        "   $\\frac{dJ}{d\\theta_0} \\approx \\frac{\\tilde{J}-J}{\\epsilon}$\n",
        "\n",
        "\n",
        "\n",
        "b. forward sensitivities\n",
        "   \n",
        "   solve $A\\frac{dx}{d\\theta} = \\frac{db}{d\\theta} - \\frac{dA}{d\\theta} x$\n",
        "\n",
        "   here: $\\frac{db}{d\\theta} = I_3$\n",
        "\n",
        "   $\\frac{dA}{d\\theta}$ this is not correct, wrong shape, yet our A is fixed, thus this is 0\n",
        "\n",
        "   solve $A\\frac{dx}{d\\theta} = I_3$ for $\\frac{dx}{d\\theta}$\n",
        "\n",
        "   then $\\frac{dJ}{d\\theta} = 0^\\top$\n",
        "\n",
        "   $\\frac{\\partial J} {\\partial x} = (x - x_r)^\\top$\n",
        "\n",
        "   then $\\frac{dJ}{d\\theta} = (x - x_r)^\\top \\frac{dx}{d\\theta}$\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7a9RKMzphDsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Adjoint backward sensitivities\n",
        "\n",
        "   solve $A^\\top \\lambda = (\\frac{\\partial J}{\\partial x})^\\top = x - x_r$ for $\\lambda$\n",
        "\n",
        "   then $\\frac{dJ}{d\\theta} = \\frac{\\partial J}{\\partial \\theta} + \\lambda^\\top = \\lambda^\\top$"
      ],
      "metadata": {
        "id": "Zn3iS3QVjNUi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDkpGL4ud4if"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([\n",
        "    [10,2,1],\n",
        "    [2,5,1],\n",
        "    [1,1,3]\n",
        "])\n",
        "\n",
        "### Creating a reference solution\n",
        "b_true = np.array([5,4,3])\n",
        "x_ref = np.linalg.solve(A, b_true) # Ax = b, solve for x\n",
        "\n",
        "### [A] Solve the classical system\n",
        "b_guess = np.ones(3)\n",
        "\n",
        "x = np.linalg.solve(A, b_guess)\n",
        "J = 0.5 * (x - x_ref).T @ (x-x_ref)\n",
        "\n",
        "### [B] Obtaining gradients\n",
        "\n",
        "## [1] Adjoint sensitivities\n",
        "\n",
        "del_J__del_theta = np.zeros((1, 3))\n",
        "del_J__del_x = (x - x_ref).T\n",
        "\n",
        "d_b__d_theta = np.eye(3)\n",
        "\n",
        "# Solve adjoint system\n",
        "\n",
        "adjoint_variable = np.linalg.solve(A.T, del_J__del_x.T)\n",
        "\n",
        "# plug in\n",
        "d_J__d_theta__adjoint = del_J__del_theta + adjoint_variable.T @ d_b__d_theta\n",
        "\n",
        "print(d_J__d_theta__adjoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeMCEYV3pcb-",
        "outputId": "f3f91f52-a7e9-4e16-c77e-69b046f901aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.00415401 -0.05307211 -0.12790626]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### [1] finite differences\n",
        "\n",
        "eps = 1.0e-6\n",
        "\n",
        "d_J__d_theta_finite_difference = np.empty((1, 3))\n",
        "\n",
        "for i in range(3):\n",
        "    b_augmented = b_guess.copy()\n",
        "    b_augmented[i] += eps\n",
        "\n",
        "    x_augmented = np.linalg.solve(A, b_augmented)\n",
        "    J_augmented = 0.5 * (x_augmented - x_ref).T @ (x_augmented - x_ref)\n",
        "\n",
        "    d_J__d_theta_finite_difference[0,i] = (J_augmented - J) / eps\n",
        "\n",
        "print(d_J__d_theta_finite_difference)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGtWxYh_rFxF",
        "outputId": "79bae4c3-f4c5-4f0f-cd6b-8677240d30f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.004154   -0.05307208 -0.12790619]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### [2] forward sensitivities\n",
        "# solve forward system\n",
        "\n",
        "d_x__d_theta = np.linalg.solve(A, d_b__d_theta)\n",
        "\n",
        "d_J__d_theta_forward = del_J__del_theta + del_J__del_x @ d_x__d_theta\n",
        "\n",
        "print(d_J__d_theta_forward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrxwQ9BmskH5",
        "outputId": "5b9a77c0-2f46-4a01-af32-c523989b246c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.00415401 -0.05307211 -0.12790626]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sjgn1yWvtMgX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}